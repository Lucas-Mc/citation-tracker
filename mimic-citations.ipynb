{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. PubMed\n",
    "\n",
    "Search PubMed for papers\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pubmed/\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK25499/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lcp.reuse as reuse\n",
    "from Bio import Entrez\n",
    "from IPython.display import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_query(base_query, restriction_query):\n",
    "    return ' AND '.join([base_query, restriction_query])\n",
    "\n",
    "entrez_email = 'mimic-support@physionet.org'\n",
    "\n",
    "# Base mimic search term. Pretty stable.\n",
    "base_mimic_query = '(mimic-ii OR mimic-iii OR mimicii OR mimiciii OR mimic-2 OR mimic-3 OR mimic2 OR mimic3)'\n",
    "# Other terms added to remove false positives. The more terms added without increasing FPs, the better.\n",
    "restriction_query = '(physionet OR icu OR “intensive care” OR “critical care”)'\n",
    "# more restriction keyword ideas: clinical, database, waveform (not suitable on their own due to general mimic term)\n",
    "full_mimic_query = full_query(base_mimic_query, restriction_query)\n",
    "\n",
    "search_strings = [\n",
    "    base_mimic_query,\n",
    "    full_mimic_query\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_mimic_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = reuse.search_list(search_strings, entrez_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display number of results\n",
    "for ss in search_strings:\n",
    "    result = search_results[ss]\n",
    "    print('%s:\\n - Count: %s' % (result.search_string, result.count))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the titles to files\n",
    "write_dir = os.path.join('search_results/pubmed')\n",
    "\n",
    "base_query_file = os.path.join(write_dir, 'without-constraints.txt')\n",
    "\n",
    "with open(base_query_file, 'w') as f:\n",
    "    for line in search_results[base_mimic_query].paper_titles:\n",
    "        f.write(line+'\\n')\n",
    "\n",
    "full_query_file = os.path.join(write_dir, 'with-constraints.txt')\n",
    "with open(full_query_file, 'w') as f:\n",
    "    for line in search_results[full_mimic_query].paper_titles:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO: Create a file called without-constraints-inspected.tsv and mark the second column with T/F for true/false positives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the effect of restricting the search by additional criteria.\n",
    "# The differences show that many false positives, and a few true positives, are removed.\n",
    "reuse.showdiff(search_results[search_strings[0]],\n",
    "               search_results[search_strings[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the labelled results for the general unconstrained search query\n",
    "labelled_results = pd.read_csv(os.path.join(write_dir, 'without-constraints-inspected.tsv'), delimiter='\\t', header=None)\n",
    "false_positives = labelled_results.loc[labelled_results[1]=='F'][0].values\n",
    "true_positives = labelled_results.loc[labelled_results[1]=='T'][0].values\n",
    "print('Number of results found using the unconstrained search term:', len(labelled_results))\n",
    "print('Number of false positives:',len(false_positives))\n",
    "print('Number of true positives:',len(true_positives))\n",
    "\n",
    "constrained_titles = search_results[search_strings[1]].paper_titles\n",
    "print('\\nCompare ^ true positives with:')\n",
    "print('Number of results from the constrained search term:', len(constrained_titles))\n",
    "\n",
    "missed_papers = set(true_positives) - set(constrained_titles)\n",
    "print('Number of missed true positives:', len(missed_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at some True positives missed by the constrained search term to figure out what else you can add.\n",
    "# Write to a file to label comments.\n",
    "write_dir = os.path.join('search_results/pubmed')\n",
    "\n",
    "missed_papers_file = os.path.join(write_dir, 'missed-papers.tsv')\n",
    "\n",
    "with open(missed_papers_file, 'w') as f:\n",
    "    for line in missed_papers:\n",
    "        f.write(line+'\\n')\n",
    "\n",
    "display(missed_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Web of Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "base_mimic_query = '(mimic-ii OR mimic-iii OR mimicii OR mimiciii OR mimic-2 OR mimic-3 OR mimic2 OR mimic3)'\n",
    "restriction_query = '(physionet OR icu OR “intensive care” OR “critical care”)'\n",
    "def full_query(base_query, restriction_query):\n",
    "    return ' AND '.join([base_query, restriction_query])\n",
    "full_mimic_query = full_query(base_mimic_query, restriction_query)\n",
    "#base_search_url = 'https://apps.webofknowledge.com/WOS_GeneralSearch_input.do?product=WOS&search_mode=GeneralSearch&SID=2F46AeWkMQBRAZlzDWm&preferencesSaved='\n",
    "base_search_url = 'https://apps.webofknowledge.com/WOS_GeneralSearch_input.do?product=WOS&search_mode=GeneralSearch&SID=1AnC2UMojuKrtrl7T5R&preferencesSaved='\n",
    "\n",
    "all_titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get to the search page\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(base_search_url)\n",
    "\n",
    "# Input the query string\n",
    "time.sleep(2.5)\n",
    "searchbox = driver.find_element_by_id('value(input1)')\n",
    "searchbox.send_keys(full_mimic_query)\n",
    "\n",
    "# Search\n",
    "time.sleep(1)\n",
    "searchbutton = driver.find_element_by_css_selector('.standard-button.primary-button.large-search-button')\n",
    "searchbutton.click()\n",
    "\n",
    "# Get the total number of pages\n",
    "npages = int(driver.find_element_by_id('pageCount.top').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the titles!!!\n",
    "while True:\n",
    "    # Get the current page number\n",
    "    pagenum = int(driver.find_element_by_class_name('goToPageNumber-input').get_property('value'))\n",
    "\n",
    "    # Get the titles. This also captures the journals. So every second value is not a title.\n",
    "    elements = driver.find_elements_by_class_name('smallV110')\n",
    "\n",
    "    for e in elements[::2]:\n",
    "        all_titles.append(e.find_element_by_tag_name('value').text)\n",
    "        \n",
    "    if pagenum < npages:\n",
    "        nextbutton = driver.find_element_by_class_name('paginationNext')\n",
    "        nextbutton.click()\n",
    "    else:\n",
    "        print('Got all paper titles!')\n",
    "        driver.close()\n",
    "        break\n",
    "        \n",
    "all_titles = set(all_titles)\n",
    "#all_titles.remove('')\n",
    "all_titles = [t.lower() for t in list(all_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(all_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the titles to files\n",
    "write_dir = os.path.join('search_results/wos')\n",
    "\n",
    "full_query_file = os.path.join(write_dir, 'with-constraints.txt')\n",
    "\n",
    "with open(full_query_file, 'w') as f:\n",
    "    for line in all_titles:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SCOPUS\n",
    "\n",
    "Shit search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. IEEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import time\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "base_mimic_query = '(mimic-ii OR mimic-iii OR mimicii OR mimiciii OR mimic-2 OR mimic-3 OR mimic2 OR mimic3)'\n",
    "restriction_query = '(physionet OR icu OR “intensive care” OR “critical care”)'\n",
    "def full_query(base_query, restriction_query):\n",
    "    return ' AND '.join([base_query, restriction_query])\n",
    "full_mimic_query = full_query(base_mimic_query, restriction_query)\n",
    "base_search_url = 'http://ieeexplore.ieee.org/search/advsearch.jsp?expression-builder'\n",
    "all_titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get to the search page\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(base_search_url)\n",
    "\n",
    "# Input the query string\n",
    "searchbox = driver.find_element_by_id('expression-textarea')\n",
    "searchbox.send_keys(full_mimic_query)\n",
    "# Select the 'full text and metadata' box\n",
    "radiobutton = driver.find_element_by_id('Search_All_Text')\n",
    "radiobutton.click()\n",
    "\n",
    "# Search\n",
    "time.sleep(1)\n",
    "searchbutton = driver.find_element_by_class_name('stats-Adv_Command_search')\n",
    "searchbutton.click()\n",
    "\n",
    "# Get the total number of pages\n",
    "#npages = int(driver.find_element_by_id('pageCount.top').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the titles!!!\n",
    "while True:\n",
    "    # let the page load\n",
    "    time.sleep(2)\n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(0.5)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "        \n",
    "    # Get the titles.\n",
    "    # They are in: <h2 class=\"result-item-title\"><a class=\"ng-binding ng-scope\">title</a></h2>\n",
    "    elements = driver.find_elements_by_class_name('result-item-title')\n",
    "    for e in elements:\n",
    "        # Text may appear with \"[::sometext::]\"\n",
    "        all_titles.append(e.find_element_by_tag_name('a').get_attribute('text').replace('[::', '').replace('::]', ''))\n",
    "        # New line separated journal info and such\n",
    "        #all_titles.append(e.text.split('\\n')[0])\n",
    "    \n",
    "    # Click next page if any\n",
    "    \n",
    "    e = driver.find_element_by_class_name('next')\n",
    "    if 'disabled' in e.get_attribute('class'):\n",
    "        print('Got all paper titles!')\n",
    "        driver.close()\n",
    "        break\n",
    "    else:\n",
    "        nextbutton = driver.find_element_by_link_text('>')\n",
    "        nextbutton.click()\n",
    "\n",
    "all_titles = set(all_titles)\n",
    "all_titles = [t.lower() for t in list(all_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_titles))\n",
    "display(all_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the titles to files\n",
    "write_dir = os.path.join('search_results/ieee')\n",
    "\n",
    "full_query_file = os.path.join(write_dir, 'with-constraints.txt')\n",
    "\n",
    "with open(full_query_file, 'w') as f:\n",
    "    for line in all_titles:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Results - pubmed, wos, ieee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'search_results'\n",
    "\n",
    "combined_results = []\n",
    "for service in ['pubmed', 'wos', 'ieee']:\n",
    "    # For pubmed, get the curated true positives from the unconstrained search instead\n",
    "    if service == 'pubmed':\n",
    "        df = pd.read_csv(os.path.join(result_dir, service, 'without-constraints-inspected.tsv'), delimiter='\\t', header=None)\n",
    "        service_results = list(df.loc[df[1]=='T'][0].values)\n",
    "    # For other services, get the constrained search results\n",
    "    else:\n",
    "        with open(os.path.join(result_dir, service, 'with-constraints.txt')) as f:\n",
    "            service_results = f.readlines()\n",
    "    print('Number of results from service '+service+': '+str(len(service_results)))\n",
    "    combined_results = combined_results + [r.strip() for r in service_results]\n",
    "\n",
    "print('\\nTotal number of non-unique results: ', len(combined_results))\n",
    "combined_results = sorted(list(set(combined_results)))\n",
    "print('Total number of unique results: ', len(combined_results))\n",
    "with open(os.path.join(result_dir, 'combined', 'with-constraints.txt'), 'w') as f:\n",
    "    for r in combined_results:\n",
    "        f.write(r+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may 21 2018\n",
    "Number of results from service pubmed: 155\n",
    "Number of results from service wos: 152\n",
    "Number of results from service ieee: 322\n",
    "\n",
    "Total number of non-unique results:  629\n",
    "Total number of unique results:  456\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting to parse GS automatically failed. Below is evidence of failure. Can ignore..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N. Search Google Scholar\n",
    "\n",
    "Packages found online:\n",
    "- https://github.com/ckreibich/scholar.py\n",
    "- https://github.com/venthur/gscholar\n",
    "- https://github.com/adeel/google-scholar-scraper\n",
    "- http://code.activestate.com/recipes/523047-search-google-scholar/\n",
    "- https://github.com/erdiaker/torrequest\n",
    "- https://github.com/NikolaiT/GoogleScraper\n",
    "\n",
    "\n",
    "- https://stackoverflow.com/questions/8049520/web-scraping-javascript-page-with-python\n",
    "\n",
    "\n",
    "Query: `(\"mimic ii\" OR \"mimic iii\") AND (\"database\" OR \"clinical\" OR \"waveform\" OR ICU)`\n",
    "\n",
    "https://scholar.google.com/scholar?q=%28mimic-ii+OR+mimic-iii%29&btnG=&hl=en&as_sdt=1%2C22&as_vis=1\n",
    "\n",
    "https://scholar.google.com/scholar/help.html\n",
    "\n",
    "\n",
    "https://superuser.com/questions/565722/how-to-config-tor-to-use-a-http-socks-proxy\n",
    "\n",
    "## Requirements\n",
    "\n",
    "1. Browse with JS enabled. requests library uses http. Otherwise google will think (correctly) that you are a robot.\n",
    "2. Change IP every time, or google will block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torrequest import TorRequest\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import getpass\n",
    "import sys\n",
    "\n",
    "import stem\n",
    "import stem.connection\n",
    "\n",
    "from stem.control import Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show IP address\n",
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password=None) as tr:\n",
    "    response = tr.get('http://ipecho.net/plain')\n",
    "    print(response.text)\n",
    "    tr.reset_identity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show IP address\n",
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password=None) as tr:\n",
    "    response = tr.get('http://ipecho.net/plain')\n",
    "    print(response.text)\n",
    "    tr.reset_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password=None) as tr:\n",
    "\n",
    "    # Specify HTTP verb and url.\n",
    "    resp = tr.get('https://scholar.google.com/scholar?q=%28mimic-ii+OR+mimic-iii%29&hl=en&as_sdt=1%2C22&as_vis=1&as_ylo=2017&as_yhi=2017')\n",
    "    print(resp.text)\n",
    "\n",
    "    # Change your Tor circuit,\n",
    "    # and likely your observed IP address.\n",
    "    tr.reset_identity()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(resp.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for anchor in soup.find_all('a'):\n",
    "    print(anchor.get('href', '/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "\n",
    "webpage = urllib2.urlopen('http://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(webpage,'html.parser')\n",
    "for anchor in soup.find_all('a'):\n",
    "    print(anchor.get('href', '/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TorRequest() as tr:\n",
    "  response = tr.get('http://ipecho.net/plain')\n",
    "  print(response.text)  # not your IP address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password=None) as tr:\n",
    "\n",
    "  # Specify HTTP verb and url.\n",
    "  resp = tr.get('https://scholar.google.com/scholar?q=%28mimic-ii+OR+mimic-iii%29&hl=en&as_sdt=1%2C22&as_vis=1&as_ylo=2017&as_yhi=2017')\n",
    "  print(resp.text)\n",
    "\n",
    "#   # Send data. Use basic authentication.\n",
    "#   resp = tr.post('https://api.example.com', \n",
    "#     data={'foo': 'bar'}, auth=('user', 'pass'))'\n",
    "#   print(resp.json)\n",
    "\n",
    "  # Change your Tor circuit,\n",
    "  # and likely your observed IP address.\n",
    "  tr.reset_identity()\n",
    "\n",
    "  # TorRequest object also exposes the underlying Stem controller \n",
    "  # and Requests session objects for more flexibility.\n",
    "\n",
    "  print(type(tr.ctrl))            # a stem.control.Controller object\n",
    "  tr.ctrl.signal('CLEARDNSCACHE') # see Stem docs for the full API\n",
    "\n",
    "  print(type(tr.session))         # a requests.Session object\n",
    "  c = cookielib.CookieJar()\n",
    "  tr.session.cookies.update(c)    # see Requests docs for the full API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scholar_url = 'https://scholar.google.com/scholar?as_vis=1&q=sepsis+mimic-iii&hl=en&as_sdt=1,22'\n",
    "echo_ip_url = 'https://www.atagar.com/echo.php'\n",
    "test_js_url = 'http://127.0.0.1:81/test-js.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password=None) as tr:\n",
    "\n",
    "  # Specify HTTP verb and url.\n",
    "  resp = tr.get('https://scholar.google.com/scholar?q=%28mimic-ii+OR+mimic-iii%29&hl=en&as_sdt=1%2C22&as_vis=1&as_ylo=2017&as_yhi=2017')\n",
    "  print(resp.text)\n",
    "\n",
    "#   # Send data. Use basic authentication.\n",
    "#   resp = tr.post('https://api.example.com', \n",
    "#     data={'foo': 'bar'}, auth=('user', 'pass'))'\n",
    "#   print(resp.json)\n",
    "\n",
    "  # Change your Tor circuit,\n",
    "  # and likely your observed IP address.\n",
    "  tr.reset_identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pycurl\n",
    "\n",
    "import stem.process\n",
    "\n",
    "from stem.util import term\n",
    "\n",
    "SOCKS_PORT = 9000\n",
    "\n",
    "def query(url):\n",
    "  \"\"\"\n",
    "  Uses pycurl to fetch a site using the proxy on the SOCKS_PORT.\n",
    "  \"\"\"\n",
    "\n",
    "  output = io.BytesIO()\n",
    "\n",
    "  query = pycurl.Curl()\n",
    "  query.setopt(pycurl.URL, url)\n",
    "  query.setopt(pycurl.PROXY, 'localhost')\n",
    "  query.setopt(pycurl.PROXYPORT, SOCKS_PORT)\n",
    "  query.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_SOCKS5_HOSTNAME)\n",
    "  query.setopt(pycurl.WRITEFUNCTION, output.write)\n",
    "\n",
    "  try:\n",
    "    query.perform()\n",
    "    return output.getvalue()\n",
    "  except pycurl.error as exc:\n",
    "    return \"Unable to reach %s (%s)\" % (url, exc)\n",
    "\n",
    "\n",
    "# Start an instance of Tor configured to only exit through Russia. This prints\n",
    "# Tor's bootstrap information as it starts. Note that this likely will not\n",
    "# work if you have another Tor instance running.\n",
    "\n",
    "def print_bootstrap_lines(line):\n",
    "  if \"Bootstrapped \" in line:\n",
    "    print(term.format(line, term.Color.BLUE))\n",
    "\n",
    "\n",
    "print(term.format(\"Starting Tor:\\n\", term.Attr.BOLD))\n",
    "\n",
    "tor_process = stem.process.launch_tor_with_config(\n",
    "  config = {\n",
    "    'SocksPort': str(SOCKS_PORT),\n",
    "    'ExitNodes': '{ru}',\n",
    "  },\n",
    "  init_msg_handler = print_bootstrap_lines,\n",
    ")\n",
    "\n",
    "print(term.format(\"\\nChecking our endpoint:\\n\", term.Attr.BOLD))\n",
    "print(term.format(query(\"https://www.atagar.com/echo.php\"), term.Color.BLUE))\n",
    "\n",
    "tor_process.kill()  # stops tor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = query(\"https://www.atagar.com/echo.php\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dryscrape\n",
    "s = dryscrape.Session()\n",
    "s.set_proxy(port=9050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stem\n",
    "from stem.control import Controller\n",
    "from stem.process import launch_tor_with_config\n",
    "import requests\n",
    "import dryscrape\n",
    "import time\n",
    "\n",
    "class TorRequest(object):\n",
    "  def __init__(self, \n",
    "      proxy_port=9050, \n",
    "      ctrl_port=9051,\n",
    "      password=None):\n",
    "\n",
    "    self.proxy_port = proxy_port\n",
    "    self.ctrl_port = ctrl_port\n",
    "    \n",
    "    self._tor_proc = None\n",
    "    if not self._tor_process_exists():\n",
    "      self._tor_proc = self._launch_tor()\n",
    "\n",
    "    self.ctrl = Controller.from_port(port=self.ctrl_port)\n",
    "    self.ctrl.authenticate(password=password)\n",
    "\n",
    "    self.session = requests.Session()\n",
    "    self.session.proxies.update({\n",
    "      'http': 'socks5://localhost:%d' % self.proxy_port,\n",
    "      'https:': 'socks5://localhost:%d' % self.proxy_port,\n",
    "    })\n",
    "\n",
    "  def _tor_process_exists(self):\n",
    "    try:\n",
    "      ctrl = Controller.from_port(port=self.ctrl_port)\n",
    "      ctrl.close()\n",
    "      return True\n",
    "    except:\n",
    "      return False\n",
    "\n",
    "  def _launch_tor(self):\n",
    "    return launch_tor_with_config(\n",
    "      config={\n",
    "        'SocksPort': str(self.proxy_port),\n",
    "        'ControlPort': str(self.ctrl_port)\n",
    "      },\n",
    "      take_ownership=True)\n",
    "\n",
    "  def close(self):\n",
    "    try: \n",
    "      self.session.close()\n",
    "    except: pass\n",
    "\n",
    "    try: \n",
    "      self.ctrl.close()\n",
    "    except: pass\n",
    "\n",
    "    if self._tor_proc:\n",
    "      self._tor_proc.terminate()\n",
    "\n",
    "  def reset_identity_async(self):\n",
    "    self.ctrl.signal(stem.Signal.NEWNYM)\n",
    "\n",
    "  def reset_identity(self):\n",
    "    self.reset_identity_async()\n",
    "    time.sleep(self.ctrl.get_newnym_wait())\n",
    "\n",
    "  def get(self, *args, **kwargs):\n",
    "    return self.session.get(*args, **kwargs)\n",
    "\n",
    "  def post(self, *args, **kwargs):\n",
    "    return self.session.post(*args, **kwargs)\n",
    "\n",
    "  def put(self, *args, **kwargs):\n",
    "    return self.session.put(*args, **kwargs)\n",
    "\n",
    "  def patch(self, *args, **kwargs):\n",
    "    return self.session.patch(*args, **kwargs)\n",
    "    \n",
    "  def delete(self, *args, **kwargs):\n",
    "    return self.session.delete(*args, **kwargs)\n",
    "\n",
    "  def __enter__(self):\n",
    "    return self\n",
    "\n",
    "  def __exit__(self, *args):\n",
    "    self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show IP address\n",
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password='16:872860B76453A77D60CA2BB8C1A7042072093276A3D701AD684053EC4C') as tr:\n",
    "    response = tr.get('http://ipecho.net/plain')\n",
    "    print(response.text)\n",
    "    tr.reset_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dryscrape\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "scholar_url = 'https://scholar.google.com/scholar?as_vis=1&q=sepsis+mimic-iii&hl=en&as_sdt=1,22'\n",
    "echo_ip_url = 'http://ipecho.net/plain'\n",
    "test_js_url = 'http://127.0.0.1:81/test-js.html'\n",
    "\n",
    "if 'linux' in sys.platform:\n",
    "    # start xvfb in case no X is running. Make sure xvfb \n",
    "    # is installed, otherwise this won't work!\n",
    "    dryscrape.start_xvfb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dryscrape.Session()\n",
    "s.visit(test_js_url)\n",
    "s.body()\n",
    "\n",
    "#s.visit('https://scholar.google.com/scholar?as_vis=1&q=sepsis+mimic-iii&hl=en&as_sdt=1,22')\n",
    "# waiting for the first data row in a table to be present\n",
    "# s.wait_for(lambda: s.at_css(\"tr.data-row0\"))\n",
    "\n",
    "# soup = BeautifulSoup(s.body(), 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dryscrape.Session()\n",
    "\n",
    "s.set_proxy(host = \"localhost\", port = 8118)\n",
    "#time.sleep(20)\n",
    "s.visit(echo_ip_url)\n",
    "#s.body()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.body()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
