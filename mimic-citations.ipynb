{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. PubMed\n",
    "\n",
    "Search PubMed for papers\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pubmed/\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK25499/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import lcp.reuse as reuse\n",
    "from Bio import Entrez\n",
    "from IPython.display import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_query(base_query, restriction_query):\n",
    "    return ' AND '.join([base_query, restriction_query])\n",
    "\n",
    "entrez_email = 'mimic-support@physionet.org'\n",
    "\n",
    "# Base mimic search term. Pretty stable.\n",
    "base_mimic_query = '(mimic-ii OR mimic-iii OR mimicii OR mimiciii OR mimic-2 OR mimic-3 OR mimic2 OR mimic3)'\n",
    "# Other terms added to remove false positives. The more terms added without increasing FPs, the better.\n",
    "restriction_query = '(physionet OR icu OR “intensive care” OR “critical care”)'\n",
    "# more restriction keyword ideas: clinical, database, waveform (not suitable on their own due to general mimic term)\n",
    "full_mimic_query = full_query(base_mimic_query, restriction_query)\n",
    "\n",
    "search_strings = [\n",
    "    base_mimic_query,\n",
    "    full_mimic_query\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(mimic-ii OR mimic-iii OR mimicii OR mimiciii OR mimic-2 OR mimic-3 OR mimic2 OR mimic3) AND (physionet OR icu OR “intensive care” OR “critical care”)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mimic_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_results = reuse.search_list(search_strings, entrez_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display number of results\n",
    "for ss in search_strings:\n",
    "    result = search_results[ss]\n",
    "    print('%s:\\n - Count: %s' % (result.search_string, result.count))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the titles to files\n",
    "write_dir = os.path.join('search_results/pubmed')\n",
    "\n",
    "base_query_file = os.path.join(write_dir, 'without-constraints.txt')\n",
    "\n",
    "with open(base_query_file, 'w') as f:\n",
    "    for line in search_results[base_mimic_query].paper_titles:\n",
    "        f.write(line+'\\n')\n",
    "\n",
    "full_query_file = os.path.join(write_dir, 'with-constraints.txt')\n",
    "with open(full_query_file, 'w') as f:\n",
    "    for line in search_results[full_mimic_query].paper_titles:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO: Create a file called without-constraints-inspected.tsv and mark the second column with T/F for true/false positives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at the effect of restricting the search by additional criteria.\n",
    "# The differences show that many false positives, and a few true positives, are removed.\n",
    "reuse.showdiff(search_results[search_strings[0]],\n",
    "               search_results[search_strings[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the labelled results for the general unconstrained search query\n",
    "labelled_results = pd.read_csv(os.path.join(write_dir, 'without-constraints-inspected.tsv'), delimiter='\\t', header=None)\n",
    "false_positives = labelled_results.loc[labelled_results[1]=='F'][0].values\n",
    "true_positives = labelled_results.loc[labelled_results[1]=='T'][0].values\n",
    "print('Number of results found using the unconstrained search term:', len(labelled_results))\n",
    "print('Number of false positives:',len(false_positives))\n",
    "print('Number of true positives:',len(true_positives))\n",
    "\n",
    "constrained_titles = search_results[search_strings[1]].paper_titles\n",
    "print('\\nCompare ^ true positives with:')\n",
    "print('Number of results from the constrained search term:', len(constrained_titles))\n",
    "\n",
    "missed_papers = set(true_positives) - set(constrained_titles)\n",
    "print('Number of missed true positives:', len(missed_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a look at some True positives missed by the constrained search term to figure out what else you can add.\n",
    "# Write to a file to label comments.\n",
    "write_dir = os.path.join('search_results/pubmed')\n",
    "\n",
    "missed_papers_file = os.path.join(write_dir, 'missed-papers.tsv')\n",
    "\n",
    "with open(missed_papers_file, 'w') as f:\n",
    "    for line in missed_papers:\n",
    "        f.write(line+'\\n')\n",
    "\n",
    "display(missed_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Web of Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "base_mimic_query = '(mimic-ii OR mimic-iii OR mimicii OR mimiciii OR mimic-2 OR mimic-3 OR mimic2 OR mimic3)'\n",
    "restriction_query = '(physionet OR icu OR “intensive care” OR “critical care”)'\n",
    "def full_query(base_query, restriction_query):\n",
    "    return ' AND '.join([base_query, restriction_query])\n",
    "full_mimic_query = full_query(base_mimic_query, restriction_query)\n",
    "#base_search_url = 'https://apps.webofknowledge.com/WOS_GeneralSearch_input.do?product=WOS&search_mode=GeneralSearch&SID=2F46AeWkMQBRAZlzDWm&preferencesSaved='\n",
    "base_search_url = 'https://apps.webofknowledge.com/WOS_GeneralSearch_input.do?product=WOS&search_mode=GeneralSearch&SID=1AnC2UMojuKrtrl7T5R&preferencesSaved='\n",
    "\n",
    "all_titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get to the search page\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(base_search_url)\n",
    "\n",
    "# Input the query string\n",
    "searchbox = driver.find_element_by_name('value(input1)')\n",
    "searchbox.send_keys(full_mimic_query)\n",
    "\n",
    "# Search\n",
    "time.sleep(1)\n",
    "searchbutton = driver.find_element_by_id('WOS_GeneralSearch_input_form_sb')\n",
    "searchbutton.click()\n",
    "\n",
    "# Get the total number of pages\n",
    "npages = int(driver.find_element_by_id('pageCount.top').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the titles!!!\n",
    "while True:\n",
    "    # Get the current page number\n",
    "    pagenum = int(driver.find_element_by_class_name('goToPageNumber-input').get_property('value'))\n",
    "\n",
    "    # Get the titles. This also captures the journals. So every second value is not a title.\n",
    "    elements = driver.find_elements_by_class_name('focus-highlight')\n",
    "\n",
    "    for e in elements[::2]:\n",
    "        all_titles.append(e.text)\n",
    "        \n",
    "    if pagenum < npages:\n",
    "        nextbutton = driver.find_element_by_class_name('paginationNext')\n",
    "        nextbutton.click()\n",
    "    else:\n",
    "        print('Got all paper titles!')\n",
    "        driver.close()\n",
    "        break\n",
    "        \n",
    "# Sometimes pages have blank strings with class='focus-highlight' which we use to find paper titles. Remove these.\n",
    "all_titles = set(all_titles)\n",
    "all_titles.remove('')\n",
    "all_titles = [t.lower() for t in list(all_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(all_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the titles to files\n",
    "write_dir = os.path.join('search_results/wos')\n",
    "\n",
    "full_query_file = os.path.join(write_dir, 'with-constraints.txt')\n",
    "\n",
    "with open(full_query_file, 'w') as f:\n",
    "    for line in all_titles:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SCOPUS\n",
    "\n",
    "Shit search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. IEEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import time\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "base_mimic_query = '(mimic-ii OR mimic-iii OR mimicii OR mimiciii OR mimic-2 OR mimic-3 OR mimic2 OR mimic3)'\n",
    "restriction_query = '(physionet OR icu OR “intensive care” OR “critical care”)'\n",
    "def full_query(base_query, restriction_query):\n",
    "    return ' AND '.join([base_query, restriction_query])\n",
    "full_mimic_query = full_query(base_mimic_query, restriction_query)\n",
    "base_search_url = 'http://ieeexplore.ieee.org/search/advsearch.jsp?expression-builder'\n",
    "all_titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get to the search page\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(base_search_url)\n",
    "\n",
    "# Input the query string\n",
    "searchbox = driver.find_element_by_id('expression-textarea')\n",
    "searchbox.send_keys(full_mimic_query)\n",
    "# Select the 'full text and metadata' box\n",
    "radiobutton = driver.find_element_by_id('Search_All_Text')\n",
    "radiobutton.click()\n",
    "\n",
    "# Search\n",
    "time.sleep(1)\n",
    "searchbutton = driver.find_element_by_class_name('stats-Adv_Command_search')\n",
    "searchbutton.click()\n",
    "\n",
    "# Get the total number of pages\n",
    "#npages = int(driver.find_element_by_id('pageCount.top').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got all paper titles!\n"
     ]
    }
   ],
   "source": [
    "# Get the titles!!!\n",
    "while True:\n",
    "    # let the page load\n",
    "    time.sleep(2)\n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(0.5)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "        \n",
    "    # Get the titles.\n",
    "    elements = driver.find_elements_by_class_name('pure-u-22-24')\n",
    "    for e in elements:\n",
    "        # New line separated journal info and such\n",
    "        all_titles.append(e.text.split('\\n')[0])\n",
    "    \n",
    "    # Click next page if any\n",
    "    \n",
    "    e = driver.find_element_by_class_name('next')\n",
    "    if 'disabled' in e.get_attribute('class'):\n",
    "        print('Got all paper titles!')\n",
    "        driver.close()\n",
    "        break\n",
    "    else:\n",
    "        nextbutton = driver.find_element_by_link_text('>')\n",
    "        nextbutton.click()\n",
    "\n",
    "all_titles = set(all_titles)\n",
    "all_titles = [t.lower() for t in list(all_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the annotation station: an open-source technology for annotating large biomedical databases',\n",
       " 'mortality prediction of icu patients using lab test data by feature vector compaction & classification',\n",
       " 'hemodynamic-impact-based prioritization of ventricular tachycardia alarms',\n",
       " 'building artificial life for play',\n",
       " 'explicu: a web-based visualization and predictive modeling toolkit for mortality in intensive care patients',\n",
       " 'predicting postoperative acute respiratory failure in critical care using nursing notes and physiological signals',\n",
       " 'study on predicting method for acute hypotensive episodes based on wavelet transform and support vector machine',\n",
       " 'predicting icu hemodynamic instability using continuous multiparameter trends',\n",
       " 'learning score systems for patient mortality prediction in intensive care units via orthogonal matching pursuit',\n",
       " 'invited speakers',\n",
       " 'suppress false arrhythmia alarms of icu monitors using heart rate estimation based on combined arterial blood pressure and ecg analysis',\n",
       " 'the bigdawg monitoring framework',\n",
       " 'surf: subject-adaptive unsupervised ecg signal compression for wearable fitness monitors',\n",
       " 'hidden semi-markov model-based heartbeat detection using multimodal data and signal quality indices',\n",
       " 'signal quality estimation with multichannel adaptive filtering in intensive care settings',\n",
       " 'prediction of mortality in patients with sepsis using detrended fluctuation analysis of heart rate variability',\n",
       " 'improving the performance of multi-parameter patient monitors using feature mapping and decision fusion',\n",
       " 'estimating cardiac output from arterial blood pressurewaveforms: a critical evaluation using the mimic ii database',\n",
       " 'predicting ards using the mimic ii physiological database',\n",
       " 'data fusion for predicting ards using the mimic ii physiological database',\n",
       " 'implantbench: characterizing and projecting representative benchmarks for emerging bioimplantable computing',\n",
       " 'clinico-genomic data analytics for precision diagnosis and disease management',\n",
       " 'a supervised learning approach for the robust detection of heart beat in plethysmographic data',\n",
       " '–omic and electronic health record big data analytics for precision medicine',\n",
       " 'a pca based feature reduction in intracranial hypertension analysis',\n",
       " 'introducing uws - a fuzzy based word similarity function with good discrimination capability: preliminary results',\n",
       " 'photoplethysmography-based method for automatic detection of premature ventricular contractions',\n",
       " 'a rule-based temporal analysis method for online health analytics and its application for real-time detection of neonatal spells',\n",
       " 'increasing the dynamic range of a pulse oximeter using heart rate characteristics',\n",
       " 'prediction of physiological subsystem failure and its impact in the prediction of patient mortality',\n",
       " 'learning from different perspectives: robust cardiac arrest prediction via temporal transfer learning',\n",
       " 'cardiac condition monitoring through photoplethysmogram signal denoising using wearables: can we detect coronary artery disease with higher performance efficacy?',\n",
       " 'icuarm-an icu clinical decision support system using association rule mining',\n",
       " 'photoplethysmograph quality estimation through multichannel filtering',\n",
       " 'denoising and baseline correction of ecg signals using sparse representation',\n",
       " 'de-identification algorithm for free-text nursing notes',\n",
       " 'model-based estimation of the cardiac output in exercise scenario',\n",
       " 'a novel smartphone camera-led communication for clinical signal transmission in mhealth-rehabilitation system',\n",
       " 'a mortality study for icu patients using bursty medical events',\n",
       " 'predicting the occurrence of acute hypotensive episodes: the physionet challenge',\n",
       " 'cross-engine query execution in federated database systems',\n",
       " 'mining the clinical narrative: all text are not equal',\n",
       " 'discovering shared dynamics in physiological signals: application to patient monitoring in icu',\n",
       " 'phenotyping hypotensive patients in critical care using hospital discharge summaries',\n",
       " 'physionet: physiologic signals, time series and related open source software for basic, clinical, and applied research',\n",
       " 'simultaneous prognosis and exploratory analysis of multiple chronic conditions using clinical notes',\n",
       " 'a sensor network query processing system for healthcare data acquisition in dr. m',\n",
       " 'coronary artery disease detection using photoplethysmography',\n",
       " 'frequency tree clustering for icu mortality analytics using graph databases',\n",
       " 'a research infrastructure for real-time evaluation of predictive algorithms for intensive care units',\n",
       " 'sparse hierarchical tucker factorization and its application to healthcare',\n",
       " 'survey of clinical data mining applications on big data in health informatics',\n",
       " 'the obesity paradox in icu patients',\n",
       " 'notice of violation of ieee publication principles',\n",
       " 'can cluster-boosted regression improve prediction of death and length of stay in the icu?',\n",
       " 'modelling intracranial pressure with noninvasive physiological measures',\n",
       " 'data preprocessing and mortality prediction: the physionet/cinc 2012 challenge revisited',\n",
       " 'necessity of laboratory blood tests in intensive care unit using data mining',\n",
       " 'a rule-based approach for the prediction of acute hypotensive episodes',\n",
       " 'highly personalized health services using cloud and sensors',\n",
       " 'a robust approach toward recognizing valid arterial-blood-pressure pulses',\n",
       " 'data analytics in ubiquitous sensor-based health information systems',\n",
       " 'discovering quantitative temporal functional dependencies on clinical data',\n",
       " 'the effect of signal quality on six cardiac output estimators',\n",
       " 'predicting occurrences of acute hypoglycemia during insulin therapy in the intensive care unit',\n",
       " 'a fault-tolerant hardware architecture for robust wearable heart rate monitoring',\n",
       " 'on robust extraction of pulse transit time from multimodal pulsatile signals',\n",
       " 'comparison of different signal processing methods for reducing artifacts from photoplethysmograph signal',\n",
       " 'wavelet based time series forecast with application to acute hypotensive episodes prediction',\n",
       " 'a probabilistic model for early prediction of abnormal clinical events using vital sign correlations in home-based monitoring',\n",
       " 'waveformecg: a platform for visualizing, annotating, and analyzing ecg data',\n",
       " 'a semi-supervised approach for temporal information extraction from clinical text',\n",
       " 'multi-probe random projection clustering to secure very large distributed datasets',\n",
       " 'an accurate mortality prediction method based on decision-level fusion of existing icu scoring systems',\n",
       " 'prediction of acute hypotension episodes using logistic regression model and support vector machine: a comparative study',\n",
       " 'detecting dynamical changes in vital signs using switching kalman filter',\n",
       " 'real-time prognosis of icu physiological data streams',\n",
       " 'clinical named entity recognition: challenges and opportunities',\n",
       " 'integrating data, models, and reasoning in critical care',\n",
       " 'bayesian networks for cardiovascular monitoring',\n",
       " 'hypotension risk prediction via sequential contrast patterns of icu blood pressure',\n",
       " 'prediction of acute hypotensive episodes using neural network multi-models',\n",
       " 'assessing the comorbidity gap between clinical studies and prevalence in elderly patient populations',\n",
       " 'a novel algorithm for reducing false arrhythmia alarms in intensive care units',\n",
       " 'heuristics to determine ventilation times of icu patients from the mimic-ii database',\n",
       " 'determining levels of arousal using electrocardiography: a study of hrv during transcranial magnetic stimulation',\n",
       " 'predicting acute hypotensive episodes: the 10th annual physionet/computers in cardiology challenge',\n",
       " 'lightweight lossy compression of biometric patterns via denoising autoencoders',\n",
       " 'suppression of false arrhythmia alarms using ecg and pulsatile waveforms',\n",
       " 'a 54-μw fast-settling arterial pulse wave sensor for wrist watch type system',\n",
       " 'empirical modelling for dynamic visualization of icu patient data streams',\n",
       " 'primary study for detection of arterial blood pressure waveform components',\n",
       " 'a decision support system for icu readmissions prevention',\n",
       " 'identification of ecg signal pattern changes to reduce the incidence of ventricular tachycardia false alarms',\n",
       " 'predicting hypoglycemia in diabetic patients using data mining techniques',\n",
       " 'on how to extract breathing rate from ppg signal using wearable devices',\n",
       " 'survival topic models for predicting outcomes for trauma patients',\n",
       " 'life-threatening arrhythmia verification in icu patients using the joint cardiovascular dynamical model and a bayesian filter',\n",
       " 'classification of photoplethysmogram signal using self organizing map',\n",
       " 'mimic ii: a massive temporal icu patient database to support research in intelligent patient monitoring',\n",
       " 'a temporal search engine for a massive multi-parameter clinical information database',\n",
       " 'toward a robust estimation of respiratory rate from pulse oximeters',\n",
       " 'cuff-less high-accuracy calibration-free blood pressure estimation using pulse transit time',\n",
       " 'mixed fuzzy clustering for misaligned time series',\n",
       " 'detection of acute hypotensive episodes via empirical mode decomposition and genetic programming',\n",
       " 'using the blood pressure waveform to reduce critical false ecg alarms',\n",
       " 'acceleration plethysmogram based biometric identification',\n",
       " 'sparse representation of photoplethysmogram using k-svd for cuffless estimation of arterial blood pressure',\n",
       " 'abp peak detection using energy analysis technique',\n",
       " 'multi-view non-negative tensor factorization as relation learning in healthcare data',\n",
       " 'toward lightweight biometric signal processing for wearable devices',\n",
       " 'fuzzy preprocessing of medical text annotations of intensive care units patients',\n",
       " 'implementation of artifact detection in critical care: a methodological review',\n",
       " 'respiration signal extraction from photoplethysmogram using pulse wave amplitude variation',\n",
       " 'latent topic discovery of clinical concepts from hospital discharge summaries of a heterogeneous patient cohort',\n",
       " 'application-specific fine tuning of multi-parameter patient monitors',\n",
       " 'threshold tuning-based wearable sensor fault detection for reliable medical monitoring using bayesian network model',\n",
       " 'collision frequency locality-sensitive hashing for prediction of critical events',\n",
       " 'ensemble fuzzy classifiers design using weighted aggregation criteria',\n",
       " 'reducing false asystole alarms in intensive care',\n",
       " 'takagi-sugeno fuzzy modeling using mixed fuzzy clustering',\n",
       " 'computing network-based features from physiological time series: application to sepsis detection',\n",
       " 'the use of data mining techniques to predict mortality and length of stay in an icu',\n",
       " 'stochastic modeling of the ppg signal: a synthesis-by-analysis approach with applications',\n",
       " 'practical aspects of manufacturing millimeter wave products in a “real world” environment',\n",
       " 'estimation of missing values in clinical laboratory measurements of icu patients using a weighted k-nearest neighbors algorithm',\n",
       " 'predicting in-hospital mortality of icu patients: the physionet/computing in cardiology challenge 2012',\n",
       " 'multivariate temporal symptomatic characterization of cardiac arrest',\n",
       " 'heart rate variability discovery: algorithm for detection of heart rate from noisy, multimodal recordings',\n",
       " 'similarity-based searching in multi-parameter time series databases',\n",
       " 'supervised learning techniques for analysis of neonatal data',\n",
       " 'text classification-based automatic recruitment of patients for clinical trials: a silver standards-based case study',\n",
       " 'patient prognosis from vital sign time series: combining convolutional neural networks with a dynamical systems approach',\n",
       " 'the bigdawg polystore system and architecture',\n",
       " 'parametric model between pulse transit time and systolic and diastolic blood pressures for non-invasive blood pressure estimation',\n",
       " 'uncovering clinical significance of vital sign dynamics in critical care',\n",
       " 'cardiovascular risk and status assessment',\n",
       " 'multivariable analysis of sedation, activity, and agitation in critically ill patients using the riker scale ecg, blood pressure, and respiratory rate',\n",
       " 'hypotension as a risk factor for acute kidney injury in icu patients',\n",
       " 'open-access mimic-ii database for intensive care research',\n",
       " 'a model-based machine learning approach to probing autonomic regulation from nonstationary vital-signs time series',\n",
       " 'lossless compression technique for real-time photoplethysmographic measurements',\n",
       " 'heterogeneous postsurgical data analytics for predictive modeling of mortality risks in intensive care units',\n",
       " 'malicious behavior monitoring of embedded medical devices',\n",
       " 'a biosignal analysis system applied for developing an algorithm predicting critical situations of high risk cardiac patients by hemodynamic monitoring',\n",
       " 'computer-assisted de-identification of free text in the mimic ii database',\n",
       " 'reconstruction of ecg signals in presence of corruption',\n",
       " 'a fast and memory-efficient algorithm for learning and retrieval of phenotypic dynamics in multivariate cohort time series',\n",
       " 'a multiple-input multiple-output system for modeling the cardiac dynamics',\n",
       " 'localized supervised metric learning on temporal physiological data',\n",
       " 'an analysis of the errors in recorded heart rate and blood pressure in the icu using a complex set of signal quality metrics',\n",
       " 'machine learning-based clinical decision support system for early diagnosis from real-time physiological data',\n",
       " 'hemodynamic monitoring using switching autoregressive dynamics of multivariate vital sign time series',\n",
       " 'machine learning and decision support in critical care',\n",
       " 'multimodeling for the prediction of patient readmissions in intensive care units',\n",
       " 'review of big data tools for healthcare system with case study on patient database storage methodology',\n",
       " 'computers in cardiology / physionet challenge 2009: predicting acute hypotensive episodes',\n",
       " 'prediction and imputation in irregularly sampled clinical time series data using hierarchical linear dynamical models',\n",
       " 'large-scale methodological comparison of acute hypotensive episode forecasting using mimic2 physiological waveforms',\n",
       " 'mortality prediction in septic shock patients: towards new personalized models in critical care',\n",
       " 'a physiological time series dynamics-based approach to patient monitoring and outcome prediction',\n",
       " 'estimation of the patient monitor alarm rate for a quantitative analysis of new alarm settings',\n",
       " 'tracking progression of patient state of health in critical care using inferred shared dynamics in physiological time series',\n",
       " 'robust estimation of respiratory rate via ecg- and ppg-derived respiratory quality indices',\n",
       " 'protective effects of rheumatoid arthritis in septic icu patients',\n",
       " 'a data mining approach to reduce the false alarm rate of patient monitors',\n",
       " 'robust detection of heart beats in multimodal data: the physionet/computing in cardiology challenge 2014',\n",
       " 'stratified locality-sensitive hashing for accelerated physiological time series retrieval',\n",
       " 'adaptive cancellation of motion artifact in wearable biosensors',\n",
       " 'a hypotensive episode predictor for intensive care based on heart rate and blood pressure time series',\n",
       " 'predicting icu readmissions based on bedside medical text notes',\n",
       " 'short-term prediction of low kidney function in icu patients',\n",
       " 'business process reengineering of the workflows in intensive care unit supported with a tablet pc based automation system',\n",
       " 'personalized mortality prediction for the critically ill using a patient similarity metric and bagging',\n",
       " 'reducing false arrhythmia alarms of patient monitoring systems in intensive care units',\n",
       " 'fuzzy modeling to predict administration of vasopressors in intensive care unit patients',\n",
       " 'risk prediction for heart failure incidence within 1-year using clinical and laboratory factors',\n",
       " 'd4m: bringing associative arrays to database engines',\n",
       " 'coefficient-free blood pressure estimation based on pulse transit time–cuff pressure dependence',\n",
       " 'cuff-less ppg based continuous blood pressure monitoring — a smartphone based approach',\n",
       " 'continuous cardiac output and left atrial pressure monitoring by pulmonary artery pressure waveform analysis',\n",
       " 'robust monitoring of hypovolemia in intensive care patients using photoplethysmogram signals',\n",
       " 'detection of new drug indications from electronic medical records',\n",
       " 'rate-distortion classification for self-tuning iot networks',\n",
       " 'early warnings of heart rate deterioration',\n",
       " 'suppression of intensive care unit false alarms based on the arterial blood pressure signal',\n",
       " 'exploring missing data prediction in medical monitoring: a performance analysis approach',\n",
       " 'automatic premature ventricular contraction detection in photoplethysmographic signals',\n",
       " 'automated feature learning: mining unstructured data for useful abstractions',\n",
       " 'boosting the battery life of wearables for health monitoring through the compression of biosignals',\n",
       " 'an algorithm for real-time pulse waveform segmentation and artifact detection in photoplethysmograms',\n",
       " 'patient flow prediction via discriminative learning of mutually-correcting processes (extended abstract)',\n",
       " 'predicting complications in critical care using heterogeneous clinical data',\n",
       " 'the physionet/computing in cardiology challenge 2010: mind the gap',\n",
       " 'generalized precursor pattern discovery for biomedical signals',\n",
       " 'towards enhancing the performance of multi-parameter patient monitors',\n",
       " 'secondary peak detection of ppg signal for continuous cuffless arterial blood pressure measurement',\n",
       " 'finding relevant cases in large databases of signals, time series, and clinical data',\n",
       " 'fuzzy modeling based on mixed fuzzy clustering for health care applications',\n",
       " 'scalable joint models for reliable uncertainty-aware event prediction',\n",
       " 'an intelligent hybrid hemodynamic data monitoring for post-cardiac surgical patients',\n",
       " 'is there opportunity for automated decision-support and closed-loop control in icu patients receiving vasopressor infusion?',\n",
       " 'ecg analysis in the time-frequency domain',\n",
       " 'finding needles in a haystack: reducing false alarm rate using telemedicine mobile cloud',\n",
       " 'prediction of mean arterial blood pressure with linear stochastic models',\n",
       " 'prediction of mortality from respiratory distress among long-term mechanically ventilated patients',\n",
       " 'optimal medication dosing from suboptimal clinical examples: a deep reinforcement learning approach',\n",
       " 'false alarm suppression in early prediction of cardiac arrhythmia',\n",
       " 'binary fish school search applied to feature selection: application to icu readmissions',\n",
       " 'ecg signal quality during arrhythmia and its application to false alarm reduction',\n",
       " 'iterative unified clustering in big data',\n",
       " 'matching data fragments with imperfect identifiers from disparate sources',\n",
       " 'an open-source, interactive java-based system for rapid encoding of significant events in the icu using the unified medical language system',\n",
       " 'robust control design for automatic regulation of blood pressure',\n",
       " 'improving the performance of continuous non-invasive estimation of blood pressure using ecg and ppg',\n",
       " 'cycle-averaged models of cardiovascular dynamics',\n",
       " 'on the use of the incremental support vector machines for monitoring systems in intensive care unit',\n",
       " 'ann validation system for icu neonatal data',\n",
       " 'prediction using patient comparison vs. modeling: a case study for mortality prediction',\n",
       " 'data mining and modeling to predict the necessity of vasopressors for icu patients',\n",
       " 'sequential pattern mining of electronic healthcare reimbursement claims: experiences and challenges in uncovering how patients are treated by physicians',\n",
       " 'predicting respiratory instability in the icu',\n",
       " 'a visualization of evolving clinical sentiment using vector representations of clinical notes',\n",
       " 'data transformation and migration in polystores',\n",
       " 'automated classification of coronary atherosclerosis using single lead ecg',\n",
       " 'a method for prediction of acute hypotensive episodes in icu via pso and k-means',\n",
       " 'feature selection and oversampling in analysis of clinical data for extubation readiness in extreme preterm infants',\n",
       " 'efficient execution methods of pivoting for bulk extraction of entity-attribute-value-modeled data',\n",
       " 'predicting short-term icu outcomes using a sequential contrast motif based classification framework',\n",
       " 'integrating real-time and batch processing in a polystore',\n",
       " 'a system for mining temporal physiological data streams for advanced prognostic decision support',\n",
       " 'a multimodal approach to reduce false arrhythmia alarms in the intensive care unit',\n",
       " 'analysis of locality-sensitive hashing for fast critical event prediction on physiological time series',\n",
       " 'advanced emd method using variance characterization for ppg with motion artifact',\n",
       " 'blood oxygen saturation alarm level analysis during mechanical lung ventilation',\n",
       " 'model selection for the pulse decomposition analysis of fingertip photoplethysmograms',\n",
       " 'analysis of the clinical utility of algorithms in the 2009 physionet/computing in cardiology challenge for the prediction of acute hypotensive episodes',\n",
       " 'online scheduling and interference alleviation for low-latency, high-throughput processing of data streams',\n",
       " 'open questions on unified approach for calibration of oscillometric blood pressure measurement devices',\n",
       " 'a machine learning approach to false alarm detection for critical arrhythmia alarms',\n",
       " 'predictive models for severe sepsis in adult icu patients',\n",
       " 'robust heart beat detection from photoplethysmography interlaced with motion artifacts based on empirical mode decomposition',\n",
       " 'the performance of neural network in the estimation of cardiac output using arterial blood pressure waveforms',\n",
       " 'incremental real time support vector machines for health monitoring system',\n",
       " 'prediction of extubation failure for neonates with respiratory distress syndrome using the mimic-ii clinical database',\n",
       " 'cardiac output monitoring in intensive care patients by radial artery pressure waveform analysis',\n",
       " 'predictive monitoring for early detection of subacute potentially catastrophic illnesses in critical care',\n",
       " 'classification of ecg signals of normal and abnormal subjects using common spatial pattern',\n",
       " 'large-scale physiological waveform retrieval via locality-sensitive hashing',\n",
       " 'leveraging mobile cloud for telemedicine: a performance study in medical monitoring',\n",
       " 'designing reliable cohorts of cardiac patients across mimic and eicu',\n",
       " 'an informatics architecture for the virtual pediatric intensive care unit',\n",
       " 'optimization of sepsis risk assessment for ward patients',\n",
       " 'model-based data integration in clinical environments',\n",
       " 'multiscale entropy and poincare plot-based analysis of pulse rate variability and heart rate variability of icu patients',\n",
       " 'vital sign normalisation for improving performance of multi-parameter patient monitors',\n",
       " 'using demographic and time series physiological features to classify sepsis in the intensive care unit',\n",
       " 'evaluation of monitoring cardiac output by long time interval analysis of a radial arterial blood pressure waveform using the mimic ii database',\n",
       " 'incremental support vector machines for monitoring systems in intensive care unit',\n",
       " 'fuzzy modeling to predict short and long-term mortality among patients with acute kidney injury',\n",
       " 'computational intelligence methods for processing misaligned, unevenly sampled time series containing missing data',\n",
       " 'closing the data loop: an integrated open access analysis platform for the mimic database',\n",
       " 'classification with imbalance: a similarity-based method for predicting respiratory failure',\n",
       " 'cuffless blood pressure estimation algorithms for continuous health-care monitoring',\n",
       " 'predicting laboratory testing in intensive care using fuzzy and neural modeling',\n",
       " 'heuristic approaches for generating local process models through log projections',\n",
       " 'pulse spectral analysis from intensive care unit patients',\n",
       " 'the learning intelligent distribution agent (lida) and medical agent x (max): computational intelligence for medical diagnosis',\n",
       " 'the effects of deep network topology on mortality prediction',\n",
       " 'segmentation of 24-hour cardiovascular activity using ecg-based sleep/sedation and noise metrics',\n",
       " 'predicting hyperlactatemia in the mimic ii database',\n",
       " 'an early respiratory distress detection method with markov models',\n",
       " 'combination of static and temporal data analysis to predict mortality and readmission in the intensive care',\n",
       " 'bdcam: big data for context-aware monitoring - a personalized knowledge discovery framework for assisted healthcare',\n",
       " 'network analysis of heart beat intervals using horizontal visibility graphs',\n",
       " 'infographic visual analytics based on empirical modelling for icu patient data streams',\n",
       " \"estimating patient's health state using latent structure inferred from clinical time series and text\",\n",
       " 'consensus motifs as adaptive and efficient predictors for acute hypotensive episodes',\n",
       " 'detecting malicious data injections in event detection wireless sensor networks',\n",
       " 'application of empirical mode decomposition in prediction of acute hypotension episodes',\n",
       " 'the progress of research on prediction model for acute hypotensive episodes',\n",
       " 'approximate temporal functional dependencies on clinical data',\n",
       " 'ubiquitous patient monitoring and smart alert generation in an intensive care unit supported by low cost tablet pc based automation system powered through open source software and hardware platforms']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(all_titles))\n",
    "display(all_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the titles to files\n",
    "write_dir = os.path.join('search_results/ieee')\n",
    "\n",
    "full_query_file = os.path.join(write_dir, 'with-constraints.txt')\n",
    "\n",
    "with open(full_query_file, 'w') as f:\n",
    "    for line in all_titles:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Results - pubmed, wos, ieee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results from service pubmed: 128\n",
      "Number of results from service wos: 133\n",
      "Number of results from service ieee: 283\n",
      "\n",
      "Total number of non-unique results:  544\n",
      "Total number of unique results:  395\n"
     ]
    }
   ],
   "source": [
    "result_dir = 'search_results'\n",
    "\n",
    "combined_results = []\n",
    "for service in ['pubmed', 'wos', 'ieee']:\n",
    "    # For pubmed, get the curated true positives from the unconstrained search instead\n",
    "    if service == 'pubmed':\n",
    "        df = pd.read_csv(os.path.join(result_dir, service, 'without-constraints-inspected.tsv'), delimiter='\\t', header=None)\n",
    "        service_results = list(df.loc[df[1]=='T'][0].values)\n",
    "    # For other services, get the constrained search results\n",
    "    else:\n",
    "        with open(os.path.join(result_dir, service, 'with-constraints.txt')) as f:\n",
    "            service_results = f.readlines()\n",
    "    print('Number of results from service '+service+': '+str(len(service_results)))\n",
    "    combined_results = combined_results + [r.strip() for r in service_results]\n",
    "\n",
    "print('\\nTotal number of non-unique results: ', len(combined_results))\n",
    "combined_results = sorted(list(set(combined_results)))\n",
    "print('Total number of unique results: ', len(combined_results))\n",
    "with open(os.path.join(result_dir, 'combined', 'with-constraints.txt'), 'w') as f:\n",
    "    for r in combined_results:\n",
    "        f.write(r+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting to parse GS automatically failed. Below is evidence of failure. Can ignore..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N. Search Google Scholar\n",
    "\n",
    "Packages found online:\n",
    "- https://github.com/ckreibich/scholar.py\n",
    "- https://github.com/venthur/gscholar\n",
    "- https://github.com/adeel/google-scholar-scraper\n",
    "- http://code.activestate.com/recipes/523047-search-google-scholar/\n",
    "- https://github.com/erdiaker/torrequest\n",
    "- https://github.com/NikolaiT/GoogleScraper\n",
    "\n",
    "\n",
    "- https://stackoverflow.com/questions/8049520/web-scraping-javascript-page-with-python\n",
    "\n",
    "\n",
    "Query: `(\"mimic ii\" OR \"mimic iii\") AND (\"database\" OR \"clinical\" OR \"waveform\" OR ICU)`\n",
    "\n",
    "https://scholar.google.com/scholar?q=%28mimic-ii+OR+mimic-iii%29&btnG=&hl=en&as_sdt=1%2C22&as_vis=1\n",
    "\n",
    "https://scholar.google.com/scholar/help.html\n",
    "\n",
    "\n",
    "https://superuser.com/questions/565722/how-to-config-tor-to-use-a-http-socks-proxy\n",
    "\n",
    "## Requirements\n",
    "\n",
    "1. Browse with JS enabled. requests library uses http. Otherwise google will think (correctly) that you are a robot.\n",
    "2. Change IP every time, or google will block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from torrequest import TorRequest\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import getpass\n",
    "import sys\n",
    "\n",
    "import stem\n",
    "import stem.connection\n",
    "\n",
    "from stem.control import Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show IP address\n",
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password=None) as tr:\n",
    "    response = tr.get('http://ipecho.net/plain')\n",
    "    print(response.text)\n",
    "    tr.reset_identity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show IP address\n",
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password=None) as tr:\n",
    "    response = tr.get('http://ipecho.net/plain')\n",
    "    print(response.text)\n",
    "    tr.reset_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password=None) as tr:\n",
    "\n",
    "    # Specify HTTP verb and url.\n",
    "    resp = tr.get('https://scholar.google.com/scholar?q=%28mimic-ii+OR+mimic-iii%29&hl=en&as_sdt=1%2C22&as_vis=1&as_ylo=2017&as_yhi=2017')\n",
    "    print(resp.text)\n",
    "\n",
    "    # Change your Tor circuit,\n",
    "    # and likely your observed IP address.\n",
    "    tr.reset_identity()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(resp.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for anchor in soup.find_all('a'):\n",
    "    print(anchor.get('href', '/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "\n",
    "webpage = urllib2.urlopen('http://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(webpage,'html.parser')\n",
    "for anchor in soup.find_all('a'):\n",
    "    print(anchor.get('href', '/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with TorRequest() as tr:\n",
    "  response = tr.get('http://ipecho.net/plain')\n",
    "  print(response.text)  # not your IP address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password=None) as tr:\n",
    "\n",
    "  # Specify HTTP verb and url.\n",
    "  resp = tr.get('https://scholar.google.com/scholar?q=%28mimic-ii+OR+mimic-iii%29&hl=en&as_sdt=1%2C22&as_vis=1&as_ylo=2017&as_yhi=2017')\n",
    "  print(resp.text)\n",
    "\n",
    "#   # Send data. Use basic authentication.\n",
    "#   resp = tr.post('https://api.example.com', \n",
    "#     data={'foo': 'bar'}, auth=('user', 'pass'))'\n",
    "#   print(resp.json)\n",
    "\n",
    "  # Change your Tor circuit,\n",
    "  # and likely your observed IP address.\n",
    "  tr.reset_identity()\n",
    "\n",
    "  # TorRequest object also exposes the underlying Stem controller \n",
    "  # and Requests session objects for more flexibility.\n",
    "\n",
    "  print(type(tr.ctrl))            # a stem.control.Controller object\n",
    "  tr.ctrl.signal('CLEARDNSCACHE') # see Stem docs for the full API\n",
    "\n",
    "  print(type(tr.session))         # a requests.Session object\n",
    "  c = cookielib.CookieJar()\n",
    "  tr.session.cookies.update(c)    # see Requests docs for the full API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scholar_url = 'https://scholar.google.com/scholar?as_vis=1&q=sepsis+mimic-iii&hl=en&as_sdt=1,22'\n",
    "echo_ip_url = 'https://www.atagar.com/echo.php'\n",
    "test_js_url = 'http://127.0.0.1:81/test-js.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password=None) as tr:\n",
    "\n",
    "  # Specify HTTP verb and url.\n",
    "  resp = tr.get('https://scholar.google.com/scholar?q=%28mimic-ii+OR+mimic-iii%29&hl=en&as_sdt=1%2C22&as_vis=1&as_ylo=2017&as_yhi=2017')\n",
    "  print(resp.text)\n",
    "\n",
    "#   # Send data. Use basic authentication.\n",
    "#   resp = tr.post('https://api.example.com', \n",
    "#     data={'foo': 'bar'}, auth=('user', 'pass'))'\n",
    "#   print(resp.json)\n",
    "\n",
    "  # Change your Tor circuit,\n",
    "  # and likely your observed IP address.\n",
    "  tr.reset_identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pycurl\n",
    "\n",
    "import stem.process\n",
    "\n",
    "from stem.util import term\n",
    "\n",
    "SOCKS_PORT = 9000\n",
    "\n",
    "def query(url):\n",
    "  \"\"\"\n",
    "  Uses pycurl to fetch a site using the proxy on the SOCKS_PORT.\n",
    "  \"\"\"\n",
    "\n",
    "  output = io.BytesIO()\n",
    "\n",
    "  query = pycurl.Curl()\n",
    "  query.setopt(pycurl.URL, url)\n",
    "  query.setopt(pycurl.PROXY, 'localhost')\n",
    "  query.setopt(pycurl.PROXYPORT, SOCKS_PORT)\n",
    "  query.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_SOCKS5_HOSTNAME)\n",
    "  query.setopt(pycurl.WRITEFUNCTION, output.write)\n",
    "\n",
    "  try:\n",
    "    query.perform()\n",
    "    return output.getvalue()\n",
    "  except pycurl.error as exc:\n",
    "    return \"Unable to reach %s (%s)\" % (url, exc)\n",
    "\n",
    "\n",
    "# Start an instance of Tor configured to only exit through Russia. This prints\n",
    "# Tor's bootstrap information as it starts. Note that this likely will not\n",
    "# work if you have another Tor instance running.\n",
    "\n",
    "def print_bootstrap_lines(line):\n",
    "  if \"Bootstrapped \" in line:\n",
    "    print(term.format(line, term.Color.BLUE))\n",
    "\n",
    "\n",
    "print(term.format(\"Starting Tor:\\n\", term.Attr.BOLD))\n",
    "\n",
    "tor_process = stem.process.launch_tor_with_config(\n",
    "  config = {\n",
    "    'SocksPort': str(SOCKS_PORT),\n",
    "    'ExitNodes': '{ru}',\n",
    "  },\n",
    "  init_msg_handler = print_bootstrap_lines,\n",
    ")\n",
    "\n",
    "print(term.format(\"\\nChecking our endpoint:\\n\", term.Attr.BOLD))\n",
    "print(term.format(query(\"https://www.atagar.com/echo.php\"), term.Color.BLUE))\n",
    "\n",
    "tor_process.kill()  # stops tor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = query(\"https://www.atagar.com/echo.php\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dryscrape\n",
    "s = dryscrape.Session()\n",
    "s.set_proxy(port=9050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import stem\n",
    "from stem.control import Controller\n",
    "from stem.process import launch_tor_with_config\n",
    "import requests\n",
    "import dryscrape\n",
    "import time\n",
    "\n",
    "class TorRequest(object):\n",
    "  def __init__(self, \n",
    "      proxy_port=9050, \n",
    "      ctrl_port=9051,\n",
    "      password=None):\n",
    "\n",
    "    self.proxy_port = proxy_port\n",
    "    self.ctrl_port = ctrl_port\n",
    "    \n",
    "    self._tor_proc = None\n",
    "    if not self._tor_process_exists():\n",
    "      self._tor_proc = self._launch_tor()\n",
    "\n",
    "    self.ctrl = Controller.from_port(port=self.ctrl_port)\n",
    "    self.ctrl.authenticate(password=password)\n",
    "\n",
    "    self.session = requests.Session()\n",
    "    self.session.proxies.update({\n",
    "      'http': 'socks5://localhost:%d' % self.proxy_port,\n",
    "      'https:': 'socks5://localhost:%d' % self.proxy_port,\n",
    "    })\n",
    "\n",
    "  def _tor_process_exists(self):\n",
    "    try:\n",
    "      ctrl = Controller.from_port(port=self.ctrl_port)\n",
    "      ctrl.close()\n",
    "      return True\n",
    "    except:\n",
    "      return False\n",
    "\n",
    "  def _launch_tor(self):\n",
    "    return launch_tor_with_config(\n",
    "      config={\n",
    "        'SocksPort': str(self.proxy_port),\n",
    "        'ControlPort': str(self.ctrl_port)\n",
    "      },\n",
    "      take_ownership=True)\n",
    "\n",
    "  def close(self):\n",
    "    try: \n",
    "      self.session.close()\n",
    "    except: pass\n",
    "\n",
    "    try: \n",
    "      self.ctrl.close()\n",
    "    except: pass\n",
    "\n",
    "    if self._tor_proc:\n",
    "      self._tor_proc.terminate()\n",
    "\n",
    "  def reset_identity_async(self):\n",
    "    self.ctrl.signal(stem.Signal.NEWNYM)\n",
    "\n",
    "  def reset_identity(self):\n",
    "    self.reset_identity_async()\n",
    "    time.sleep(self.ctrl.get_newnym_wait())\n",
    "\n",
    "  def get(self, *args, **kwargs):\n",
    "    return self.session.get(*args, **kwargs)\n",
    "\n",
    "  def post(self, *args, **kwargs):\n",
    "    return self.session.post(*args, **kwargs)\n",
    "\n",
    "  def put(self, *args, **kwargs):\n",
    "    return self.session.put(*args, **kwargs)\n",
    "\n",
    "  def patch(self, *args, **kwargs):\n",
    "    return self.session.patch(*args, **kwargs)\n",
    "    \n",
    "  def delete(self, *args, **kwargs):\n",
    "    return self.session.delete(*args, **kwargs)\n",
    "\n",
    "  def __enter__(self):\n",
    "    return self\n",
    "\n",
    "  def __exit__(self, *args):\n",
    "    self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show IP address\n",
    "with TorRequest(proxy_port=9050, ctrl_port=9051, password='16:872860B76453A77D60CA2BB8C1A7042072093276A3D701AD684053EC4C') as tr:\n",
    "    response = tr.get('http://ipecho.net/plain')\n",
    "    print(response.text)\n",
    "    tr.reset_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dryscrape\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "scholar_url = 'https://scholar.google.com/scholar?as_vis=1&q=sepsis+mimic-iii&hl=en&as_sdt=1,22'\n",
    "echo_ip_url = 'http://ipecho.net/plain'\n",
    "test_js_url = 'http://127.0.0.1:81/test-js.html'\n",
    "\n",
    "if 'linux' in sys.platform:\n",
    "    # start xvfb in case no X is running. Make sure xvfb \n",
    "    # is installed, otherwise this won't work!\n",
    "    dryscrape.start_xvfb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = dryscrape.Session()\n",
    "s.visit(test_js_url)\n",
    "s.body()\n",
    "\n",
    "#s.visit('https://scholar.google.com/scholar?as_vis=1&q=sepsis+mimic-iii&hl=en&as_sdt=1,22')\n",
    "# waiting for the first data row in a table to be present\n",
    "# s.wait_for(lambda: s.at_css(\"tr.data-row0\"))\n",
    "\n",
    "# soup = BeautifulSoup(s.body(), 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = dryscrape.Session()\n",
    "\n",
    "s.set_proxy(host = \"localhost\", port = 8118)\n",
    "#time.sleep(20)\n",
    "s.visit(echo_ip_url)\n",
    "#s.body()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.body()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
